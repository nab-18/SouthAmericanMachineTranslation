{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nabeelparuk/south-american-translator-with-keras-nlp-in-prog?scriptVersionId=195818989\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"fee447ba","metadata":{"papermill":{"duration":0.02536,"end_time":"2024-09-08T14:13:29.258442","exception":false,"start_time":"2024-09-08T14:13:29.233082","status":"completed"},"tags":[]},"source":["# **South American Translator with Keras NLP**"]},{"cell_type":"code","execution_count":1,"id":"9817eb50","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-08T14:13:29.310957Z","iopub.status.busy":"2024-09-08T14:13:29.310324Z","iopub.status.idle":"2024-09-08T14:13:30.210382Z","shell.execute_reply":"2024-09-08T14:13:30.208989Z"},"papermill":{"duration":0.929675,"end_time":"2024-09-08T14:13:30.213339","exception":false,"start_time":"2024-09-08T14:13:29.283664","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/por-eng/por-eng/por.txt\n","/kaggle/input/por-eng/por-eng/_about.txt\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"c349b1d6","metadata":{"papermill":{"duration":0.024468,"end_time":"2024-09-08T14:13:30.26349","exception":false,"start_time":"2024-09-08T14:13:30.239022","status":"completed"},"tags":[]},"source":["## Import modules"]},{"cell_type":"code","execution_count":2,"id":"c0633347","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:13:30.317928Z","iopub.status.busy":"2024-09-08T14:13:30.31729Z","iopub.status.idle":"2024-09-08T14:14:27.143007Z","shell.execute_reply":"2024-09-08T14:14:27.141567Z"},"papermill":{"duration":56.856363,"end_time":"2024-09-08T14:14:27.146074","exception":false,"start_time":"2024-09-08T14:13:30.289711","status":"completed"},"tags":[]},"outputs":[],"source":["!pip install -q --upgrade rouge-score\n","!pip install -q --upgrade keras-nlp\n","!pip install -q --upgrade keras"]},{"cell_type":"code","execution_count":3,"id":"e20d010c","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:14:27.197313Z","iopub.status.busy":"2024-09-08T14:14:27.196847Z","iopub.status.idle":"2024-09-08T14:14:42.80103Z","shell.execute_reply":"2024-09-08T14:14:42.799841Z"},"papermill":{"duration":15.633127,"end_time":"2024-09-08T14:14:42.803826","exception":false,"start_time":"2024-09-08T14:14:27.170699","status":"completed"},"tags":[]},"outputs":[],"source":["import keras_nlp\n","import pathlib\n","import random\n","import os\n","import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf\n","import keras\n","from keras import ops\n","\n","import tensorflow.data as tf_data\n","\n","from tensorflow_text.tools.wordpiece_vocab import (\n","    bert_vocab_from_dataset as bert_vocab\n",")\n","\n","import pickle\n","\n","from sklearn.model_selection import train_test_split\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","id":"ea14cc8a","metadata":{"papermill":{"duration":0.024088,"end_time":"2024-09-08T14:14:42.852297","exception":false,"start_time":"2024-09-08T14:14:42.828209","status":"completed"},"tags":[]},"source":["# English-Spanish"]},{"cell_type":"markdown","id":"efe90b8f","metadata":{"papermill":{"duration":0.024294,"end_time":"2024-09-08T14:14:42.901194","exception":false,"start_time":"2024-09-08T14:14:42.8769","status":"completed"},"tags":[]},"source":["## Setup"]},{"cell_type":"markdown","id":"13b8745a","metadata":{"papermill":{"duration":0.024576,"end_time":"2024-09-08T14:14:42.950067","exception":false,"start_time":"2024-09-08T14:14:42.925491","status":"completed"},"tags":[]},"source":["### Define parameters and hyperparameters"]},{"cell_type":"code","execution_count":4,"id":"de40cf8b","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:14:43.001292Z","iopub.status.busy":"2024-09-08T14:14:43.000529Z","iopub.status.idle":"2024-09-08T14:14:43.007162Z","shell.execute_reply":"2024-09-08T14:14:43.005954Z"},"papermill":{"duration":0.035377,"end_time":"2024-09-08T14:14:43.009909","exception":false,"start_time":"2024-09-08T14:14:42.974532","status":"completed"},"tags":[]},"outputs":[],"source":["MAX_SEQUENCE_LENGTH = 40\n","ENG_VOCAB_SIZE = 15000\n","SPA_VOCAB_SIZE = 15000\n","POR_VOCAB_SIZE = 15000\n","AYM_VOCAB_SIZE = 15000\n","BATCH_SIZE = 64\n","EMBED_DIM = 256\n","INTERMEDIATE_DIM = 2048\n","NUM_HEADS = 8"]},{"cell_type":"markdown","id":"72cf3328","metadata":{"papermill":{"duration":0.024284,"end_time":"2024-09-08T14:14:43.058661","exception":false,"start_time":"2024-09-08T14:14:43.034377","status":"completed"},"tags":[]},"source":["### Import English-Spanish Dataset"]},{"cell_type":"code","execution_count":5,"id":"78f00e98","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:14:43.109417Z","iopub.status.busy":"2024-09-08T14:14:43.108944Z","iopub.status.idle":"2024-09-08T14:14:43.270786Z","shell.execute_reply":"2024-09-08T14:14:43.269812Z"},"papermill":{"duration":0.19061,"end_time":"2024-09-08T14:14:43.273771","exception":false,"start_time":"2024-09-08T14:14:43.083161","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n","\u001b[1m2638744/2638744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["text_file = keras.utils.get_file(\n","    fname=\"spa-eng.zip\",\n","    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n","    extract=True\n",")\n","\n","text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""]},{"cell_type":"markdown","id":"da021a03","metadata":{"papermill":{"duration":0.024398,"end_time":"2024-09-08T14:14:43.323008","exception":false,"start_time":"2024-09-08T14:14:43.29861","status":"completed"},"tags":[]},"source":["### Parse the data"]},{"cell_type":"markdown","id":"4b3eeb09","metadata":{"papermill":{"duration":0.024521,"end_time":"2024-09-08T14:14:43.372291","exception":false,"start_time":"2024-09-08T14:14:43.34777","status":"completed"},"tags":[]},"source":["* English = Source sequence\n","* Spanish = Target sequence"]},{"cell_type":"code","execution_count":6,"id":"a2add09e","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:14:43.424381Z","iopub.status.busy":"2024-09-08T14:14:43.423326Z","iopub.status.idle":"2024-09-08T14:14:43.719259Z","shell.execute_reply":"2024-09-08T14:14:43.718048Z"},"papermill":{"duration":0.324676,"end_time":"2024-09-08T14:14:43.722014","exception":false,"start_time":"2024-09-08T14:14:43.397338","status":"completed"},"tags":[]},"outputs":[],"source":["# We will add the text to a list -> But first make everything lowercase\n","with open(text_file) as f:\n","    lines = f.read().split(\"\\n\")[:-1]\n","text_pairs = []\n","\n","for line in lines:\n","    eng, spa = line.split(\"\\t\")\n","    eng = eng.lower()\n","    spa = spa.lower()\n","    text_pairs.append((eng, spa))"]},{"cell_type":"markdown","id":"2af83437","metadata":{"papermill":{"duration":0.024426,"end_time":"2024-09-08T14:14:43.771971","exception":false,"start_time":"2024-09-08T14:14:43.747545","status":"completed"},"tags":[]},"source":["#### View the sentence pairs"]},{"cell_type":"code","execution_count":7,"id":"c9f3a382","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:14:43.823623Z","iopub.status.busy":"2024-09-08T14:14:43.823208Z","iopub.status.idle":"2024-09-08T14:14:43.829628Z","shell.execute_reply":"2024-09-08T14:14:43.828513Z"},"papermill":{"duration":0.035848,"end_time":"2024-09-08T14:14:43.83257","exception":false,"start_time":"2024-09-08T14:14:43.796722","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["(\"i don't think i have one of those yet.\", 'no creo que tenga todavía uno de esos.')\n","('is that tom?', '¿es ese tom?')\n","('would you like to hear me sing a song?', '¿quieres oírme cantar?')\n","('when you watch television or listen to the radio, the music which you hear is often african in origin.', 'cuando ves televisión o escuchas la radio, la música que oyes es frecuentemente de origen africano.')\n","('tom thought it would be difficult for mary to get a ticket to that concert.', 'tom pensó que sería difícil que maría consiguiera una entrada para ese concierto.')\n"]}],"source":["for _ in range(5):\n","    print(random.choice(text_pairs))"]},{"cell_type":"markdown","id":"6b47085d","metadata":{"papermill":{"duration":0.024307,"end_time":"2024-09-08T14:14:43.881692","exception":false,"start_time":"2024-09-08T14:14:43.857385","status":"completed"},"tags":[]},"source":["## Preprocessing"]},{"cell_type":"markdown","id":"b24f9b4b","metadata":{"papermill":{"duration":0.024527,"end_time":"2024-09-08T14:14:43.93109","exception":false,"start_time":"2024-09-08T14:14:43.906563","status":"completed"},"tags":[]},"source":["### Split the data"]},{"cell_type":"code","execution_count":8,"id":"60fc1757","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:14:43.983828Z","iopub.status.busy":"2024-09-08T14:14:43.982794Z","iopub.status.idle":"2024-09-08T14:14:44.121808Z","shell.execute_reply":"2024-09-08T14:14:44.120482Z"},"papermill":{"duration":0.168423,"end_time":"2024-09-08T14:14:44.124544","exception":false,"start_time":"2024-09-08T14:14:43.956121","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Train size: 83276\n","Validation size: 17844\n","Test size: 17844\n"]}],"source":["# Shuffle the list\n","random.shuffle(text_pairs)\n","\n","# Set training and validation sizes\n","num_val_samples = int(0.15 * len(text_pairs))\n","num_train_samples = int(len(text_pairs) - 2 * num_val_samples)\n","\n","# Get train, val and test sets\n","train_pairs = text_pairs[: num_train_samples]\n","val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n","test_pairs = text_pairs[num_train_samples + num_val_samples :]\n","\n","print(f\"Train size: {len(train_pairs)}\")\n","print(f\"Validation size: {len(val_pairs)}\")\n","print(f\"Test size: {len(test_pairs)}\")"]},{"cell_type":"markdown","id":"0ae6adc3","metadata":{"papermill":{"duration":0.0248,"end_time":"2024-09-08T14:14:44.174737","exception":false,"start_time":"2024-09-08T14:14:44.149937","status":"completed"},"tags":[]},"source":["### Tokenization"]},{"cell_type":"markdown","id":"db3e65f0","metadata":{"papermill":{"duration":0.02484,"end_time":"2024-09-08T14:14:44.225557","exception":false,"start_time":"2024-09-08T14:14:44.200717","status":"completed"},"tags":[]},"source":["We need to define two tokenizers: 1 for the English (source) dataset and one for the Spanish (target) dataset\n","\n","- But first we need to train them on the dataset we have"]},{"cell_type":"markdown","id":"77befc85","metadata":{"papermill":{"duration":0.0248,"end_time":"2024-09-08T14:14:44.276072","exception":false,"start_time":"2024-09-08T14:14:44.251272","status":"completed"},"tags":[]},"source":["#### Start by generating a vocabulary for each language"]},{"cell_type":"code","execution_count":9,"id":"f38c912e","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:14:44.329325Z","iopub.status.busy":"2024-09-08T14:14:44.328837Z","iopub.status.idle":"2024-09-08T14:14:44.335508Z","shell.execute_reply":"2024-09-08T14:14:44.334274Z"},"papermill":{"duration":0.036902,"end_time":"2024-09-08T14:14:44.338193","exception":false,"start_time":"2024-09-08T14:14:44.301291","status":"completed"},"tags":[]},"outputs":[],"source":["# Use WordPiece to subword tokenize -> returns a vocabulary of subwords\n","def train_word_piece(text_samples, vocab_size, reserved_tokens):\n","    word_piece_ds = tf_data.Dataset.from_tensor_slices(text_samples)\n","    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n","        word_piece_ds.batch(1000).prefetch(2),\n","        vocabulary_size=vocab_size,\n","    reserved_tokens=reserved_tokens,\n","    )\n","    return vocab"]},{"cell_type":"markdown","id":"28ac1a65","metadata":{"papermill":{"duration":0.025061,"end_time":"2024-09-08T14:14:44.388573","exception":false,"start_time":"2024-09-08T14:14:44.363512","status":"completed"},"tags":[]},"source":["- [PAD] - Padding token\n","- [UNK] - Unknown token\n","- [START] - Token that marks the start of the input sequence\n","- [END] - Token that marks the end of the input sequence"]},{"cell_type":"code","execution_count":10,"id":"c9eb5878","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:14:44.442092Z","iopub.status.busy":"2024-09-08T14:14:44.440845Z","iopub.status.idle":"2024-09-08T14:17:35.56969Z","shell.execute_reply":"2024-09-08T14:17:35.568489Z"},"papermill":{"duration":171.158948,"end_time":"2024-09-08T14:17:35.572908","exception":false,"start_time":"2024-09-08T14:14:44.41396","status":"completed"},"tags":[]},"outputs":[],"source":["# Reserve these tokens\n","reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","# Tokenize English samples\n","eng_samples = [text_pair[0] for text_pair in train_pairs]\n","eng_vocab = train_word_piece(eng_samples, ENG_VOCAB_SIZE, reserved_tokens)\n","\n","# Tokenize Spanish samples\n","spa_samples = [text_pair[1] for text_pair in train_pairs]\n","spa_vocab = train_word_piece(spa_samples, SPA_VOCAB_SIZE, reserved_tokens)"]},{"cell_type":"code","execution_count":11,"id":"d9959994","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:35.625441Z","iopub.status.busy":"2024-09-08T14:17:35.624331Z","iopub.status.idle":"2024-09-08T14:17:35.631184Z","shell.execute_reply":"2024-09-08T14:17:35.63007Z"},"papermill":{"duration":0.035826,"end_time":"2024-09-08T14:17:35.633794","exception":false,"start_time":"2024-09-08T14:17:35.597968","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["English Tokens:  ['him', 'there', 'they', 'go', 'her', 'has', 'will', 're', 'time', 'how']\n","Spanish Tokens:  ['para', 'mary', 'las', 'más', 'al', 'yo', 'tu', 'estoy', 'muy', 'eso']\n"]}],"source":["# View some tokens\n","print(\"English Tokens: \", eng_vocab[100:110])\n","print(\"Spanish Tokens: \", spa_vocab[100:110])"]},{"cell_type":"markdown","id":"bf032e42","metadata":{"papermill":{"duration":0.024509,"end_time":"2024-09-08T14:17:35.683525","exception":false,"start_time":"2024-09-08T14:17:35.659016","status":"completed"},"tags":[]},"source":["#### Now create the tokenizers with the vocabularies we just made"]},{"cell_type":"code","execution_count":12,"id":"638b3878","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:35.73547Z","iopub.status.busy":"2024-09-08T14:17:35.735003Z","iopub.status.idle":"2024-09-08T14:17:35.843453Z","shell.execute_reply":"2024-09-08T14:17:35.842451Z"},"papermill":{"duration":0.137585,"end_time":"2024-09-08T14:17:35.846159","exception":false,"start_time":"2024-09-08T14:17:35.708574","status":"completed"},"tags":[]},"outputs":[],"source":["# English tokenizer\n","eng_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=eng_vocab, lowercase=False\n",")\n","\n","# Spanish tokenizer\n","spa_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=spa_vocab, lowercase=False\n",")"]},{"cell_type":"code","execution_count":13,"id":"08d703e9","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:35.898512Z","iopub.status.busy":"2024-09-08T14:17:35.897723Z","iopub.status.idle":"2024-09-08T14:17:35.925374Z","shell.execute_reply":"2024-09-08T14:17:35.924392Z"},"papermill":{"duration":0.057049,"end_time":"2024-09-08T14:17:35.928237","exception":false,"start_time":"2024-09-08T14:17:35.871188","status":"completed"},"tags":[]},"outputs":[],"source":["# Save tokenizers to file\n","# English\n","with open('tokenizer_engspa_eng.pickle', 'wb') as handle:\n","    pickle.dump(eng_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","    \n","# Spanish\n","with open('tokenizer_engspa_spa.pickle', 'wb') as handle:\n","    pickle.dump(spa_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":14,"id":"dc18a4b6","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:35.980762Z","iopub.status.busy":"2024-09-08T14:17:35.979758Z","iopub.status.idle":"2024-09-08T14:17:36.143412Z","shell.execute_reply":"2024-09-08T14:17:36.142153Z"},"papermill":{"duration":0.192319,"end_time":"2024-09-08T14:17:36.145948","exception":false,"start_time":"2024-09-08T14:17:35.953629","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["English Sentence:  i'll hide it somewhere.\n","Tokens:  tf.Tensor([  35    8  110  756   70 1083   12], shape=(7,), dtype=int32)\n","Recovered text after detokenizing:  tf.Tensor(b\"i ' ll hide it somewhere .\", shape=(), dtype=string)\n","\n","Spanish sentence:  lo esconderé en cualquier lugar.\n","Tokens:  tf.Tensor([  88 2610  217   81  491  335   15], shape=(7,), dtype=int32)\n","Recovered text after detokenizing: tf.Tensor(b'lo esconder\\xc3\\xa9 en cualquier lugar .', shape=(), dtype=string)\n"]}],"source":["# Lets test the tokenizers on a sample\n","# English\n","eng_input_eg = text_pairs[0][0]\n","eng_tokens_eg = eng_tokenizer.tokenize(eng_input_eg)\n","print(\"English Sentence: \", eng_input_eg)\n","print(\"Tokens: \", eng_tokens_eg)\n","print(\"Recovered text after detokenizing: \",\n","     eng_tokenizer.detokenize(eng_tokens_eg))\n","\n","print()\n","# Spanish\n","spa_input_eg = text_pairs[0][1]\n","spa_tokens_eg = spa_tokenizer.tokenize(spa_input_eg)\n","print(\"Spanish sentence: \", spa_input_eg)\n","print(\"Tokens: \", spa_tokens_eg)\n","print(\"Recovered text after detokenizing:\",\n","     spa_tokenizer.detokenize(spa_tokens_eg))"]},{"cell_type":"markdown","id":"3e5a7aa1","metadata":{"papermill":{"duration":0.024644,"end_time":"2024-09-08T14:17:36.195463","exception":false,"start_time":"2024-09-08T14:17:36.170819","status":"completed"},"tags":[]},"source":["### Format datasets"]},{"cell_type":"markdown","id":"a12bca62","metadata":{"papermill":{"duration":0.084083,"end_time":"2024-09-08T14:17:36.30451","exception":false,"start_time":"2024-09-08T14:17:36.220427","status":"completed"},"tags":[]},"source":["**We want the model to predict target words N+1 and beyond using:**\n"," - The source sentence (English)\n"," - The words up to N (words already predicted before)\n"," \n","**The training dataset will yield a tuple (inputs, targets):**\n"," -  Inputs: Dictionary with keys `encoder_inputs` and `decoder_inputs`.\n","     - `encoder_inputs` -> Tokenized source sentence\n","     - `decoder_inputs` -> Target sentence so far (what has already been predicted i.e. words up to N\n"," - Targets: target sentence offset by one step\n","     - Provides the next words in the target sentence (what the model will try to predict\n","\n","We also need to add special tokens ([START] and [END]) to the input Spanish sentence after tokenizing the text AND we need to pad input to a fixed length\n"," - This can be done using `keras_nlp.layers.StartEndPacker`"]},{"cell_type":"code","execution_count":15,"id":"748dcbfe","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:36.35682Z","iopub.status.busy":"2024-09-08T14:17:36.356362Z","iopub.status.idle":"2024-09-08T14:17:36.365409Z","shell.execute_reply":"2024-09-08T14:17:36.364369Z"},"papermill":{"duration":0.038074,"end_time":"2024-09-08T14:17:36.367833","exception":false,"start_time":"2024-09-08T14:17:36.329759","status":"completed"},"tags":[]},"outputs":[],"source":["# Define the preprocessing function\n","def preprocess_batch(eng, spa):\n","    # Batch size depending on the length of the tokens\n","    batch_size = ops.shape(spa)[0]\n","    \n","    # Tokenize\n","    eng = eng_tokenizer(eng)\n","    spa = spa_tokenizer(spa)\n","    \n","    # Pad the English tokenized data to 'MAX_SEQUENCE_LENGTH'\n","    eng_start_end_packer = keras_nlp.layers.StartEndPacker(\n","        sequence_length=MAX_SEQUENCE_LENGTH,\n","        pad_value=eng_tokenizer.token_to_id(\"[PAD]\"),\n","    )\n","    eng = eng_start_end_packer(eng)\n","    \n","    # Pad the Spanish tokenized data AND add special tokens '[START]' and '[END]'\n","    spa_start_end_packer = keras_nlp.layers.StartEndPacker(\n","        sequence_length=MAX_SEQUENCE_LENGTH + 1,\n","        start_value=spa_tokenizer.token_to_id(\"[START]\"),\n","        end_value=spa_tokenizer.token_to_id(\"[END]\"),\n","        pad_value=spa_tokenizer.token_to_id(\"[PAD]\"),\n","    )\n","    spa = spa_start_end_packer(spa)\n","    \n","    # Now return the tuple with the inputs (encoder inputs and decoder inputs in a dictionary) and the targets\n","    return (\n","        {\n","            \"encoder_inputs\": eng,\n","            \"decoder_inputs\": spa[ : , :-1]\n","        },\n","        spa[:, 1:],\n","    )"]},{"cell_type":"code","execution_count":16,"id":"2bfe5a0f","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:36.41959Z","iopub.status.busy":"2024-09-08T14:17:36.419187Z","iopub.status.idle":"2024-09-08T14:17:36.426427Z","shell.execute_reply":"2024-09-08T14:17:36.425274Z"},"papermill":{"duration":0.036137,"end_time":"2024-09-08T14:17:36.429039","exception":false,"start_time":"2024-09-08T14:17:36.392902","status":"completed"},"tags":[]},"outputs":[],"source":["# Define the dataset function\n","def make_dataset(pairs):\n","    \n","    # Get the texts for each language individually\n","    eng_texts, spa_texts = zip(*pairs)\n","    \n","    # Turn returned variables into lists\n","    eng_texts = list(eng_texts)\n","    spa_texts = list(spa_texts)\n","    \n","    # Turn it into a tf_data dataset\n","    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.map(preprocess_batch, num_parallel_calls=tf_data.AUTOTUNE)\n","    \n","    return dataset.shuffle(2048).prefetch(16).cache()"]},{"cell_type":"code","execution_count":17,"id":"c8967ba3","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:36.481002Z","iopub.status.busy":"2024-09-08T14:17:36.480556Z","iopub.status.idle":"2024-09-08T14:17:40.328052Z","shell.execute_reply":"2024-09-08T14:17:40.326916Z"},"papermill":{"duration":3.876733,"end_time":"2024-09-08T14:17:40.330958","exception":false,"start_time":"2024-09-08T14:17:36.454225","status":"completed"},"tags":[]},"outputs":[],"source":["# Create the dataset\n","train_ds = make_dataset(train_pairs)\n","val_ds = make_dataset(val_pairs)"]},{"cell_type":"code","execution_count":18,"id":"b2552548","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:40.382779Z","iopub.status.busy":"2024-09-08T14:17:40.382269Z","iopub.status.idle":"2024-09-08T14:17:41.797873Z","shell.execute_reply":"2024-09-08T14:17:41.796624Z"},"papermill":{"duration":1.444905,"end_time":"2024-09-08T14:17:41.800825","exception":false,"start_time":"2024-09-08T14:17:40.35592","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["inputs[\"encoder_inputs\"].shape: (64, 40)\n","inputs[\"decoder_inputs\"].shape: (64, 40)\n","targets.shape: (64, 40)\n"]}],"source":["# Look at sequence shapes\n","for inputs, targets in train_ds.take(1):\n","    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n","    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n","    print(f\"targets.shape: {targets.shape}\")"]},{"cell_type":"markdown","id":"5efbe568","metadata":{"papermill":{"duration":0.025187,"end_time":"2024-09-08T14:17:41.852232","exception":false,"start_time":"2024-09-08T14:17:41.827045","status":"completed"},"tags":[]},"source":["## Model Construction"]},{"cell_type":"markdown","id":"fb4df2dc","metadata":{"papermill":{"duration":0.025051,"end_time":"2024-09-08T14:17:41.902864","exception":false,"start_time":"2024-09-08T14:17:41.877813","status":"completed"},"tags":[]},"source":["**We need:**\n","- Embeddings -> The following are combined into one layer\n","    - Embedding layer\n","        - Creates a vector for every token in our sequence\n","        - Can be initialised randomly\n","    - Positional embedding layer\n","        - Encodes the word order in the sequence\n","        - With the `mask_zero` argument we can mask the padding tokens (\"[PAD]\")\n","- Seq2Seq Transformer\n","    - Consists of `TransformerEncoder` and `TransformerDecoder` layers chained together"]},{"cell_type":"markdown","id":"27c0d309","metadata":{"papermill":{"duration":0.024627,"end_time":"2024-09-08T14:17:41.953097","exception":false,"start_time":"2024-09-08T14:17:41.92847","status":"completed"},"tags":[]},"source":["**Workflow of model:**\n","1. Source sequence (English) passes to `TransformerEncoder` -> produces a new representation of it\n","2. New representation passed to `TransformerDecoder`\n","3. With the target sequence so far (what has previously been predicted from 0 to N) and `TransformerDecoder`, the new representation is used to predict the N+1th word."]},{"cell_type":"markdown","id":"593052c7","metadata":{"papermill":{"duration":0.025286,"end_time":"2024-09-08T14:17:42.003532","exception":false,"start_time":"2024-09-08T14:17:41.978246","status":"completed"},"tags":[]},"source":["**Key detail: Causal Masking**\n","- `TransformerDecoder` sees the whole sequence at once but we only want information from target tokens 0 to N when predicting N + 1\n","- Using information from the future would result in a model that can't be used in inference time"]},{"cell_type":"markdown","id":"4526b1c2","metadata":{"papermill":{"duration":0.025316,"end_time":"2024-09-08T14:17:42.054233","exception":false,"start_time":"2024-09-08T14:17:42.028917","status":"completed"},"tags":[]},"source":["### Create modelling checkpoint callback"]},{"cell_type":"code","execution_count":19,"id":"1f758f5e","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:42.107919Z","iopub.status.busy":"2024-09-08T14:17:42.107045Z","iopub.status.idle":"2024-09-08T14:17:42.11355Z","shell.execute_reply":"2024-09-08T14:17:42.112387Z"},"papermill":{"duration":0.036384,"end_time":"2024-09-08T14:17:42.116393","exception":false,"start_time":"2024-09-08T14:17:42.080009","status":"completed"},"tags":[]},"outputs":[],"source":["def create_model_checkpoint(model_name, save_path=\"/kaggle/working/model_experiments\"):\n","    return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_path, f\"{model_name}.keras\"),\n","                                            verbose=0,\n","                                            save_best_only=True)"]},{"cell_type":"markdown","id":"952cc068","metadata":{"papermill":{"duration":0.02907,"end_time":"2024-09-08T14:17:42.171443","exception":false,"start_time":"2024-09-08T14:17:42.142373","status":"completed"},"tags":[]},"source":["### Encoder"]},{"cell_type":"code","execution_count":20,"id":"d3fa0294","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:42.225384Z","iopub.status.busy":"2024-09-08T14:17:42.224416Z","iopub.status.idle":"2024-09-08T14:17:43.757845Z","shell.execute_reply":"2024-09-08T14:17:43.756495Z"},"papermill":{"duration":1.563524,"end_time":"2024-09-08T14:17:43.760711","exception":false,"start_time":"2024-09-08T14:17:42.197187","status":"completed"},"tags":[]},"outputs":[],"source":["# Use Functional API\n","# Inputs\n","encoder_inputs = keras.Input(shape=(None,), name=\"encoder_inputs\")\n","\n","# Embedding\n","x = keras_nlp.layers.TokenAndPositionEmbedding(\n","    vocabulary_size=ENG_VOCAB_SIZE,\n","    sequence_length=MAX_SEQUENCE_LENGTH,\n","    embedding_dim=EMBED_DIM\n",")(encoder_inputs)\n","\n","# Outputs\n","encoder_outputs = keras_nlp.layers.TransformerEncoder(\n","    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",")(inputs=x)\n","\n","# Define encoder\n","encoder = keras.Model(encoder_inputs, encoder_outputs)"]},{"cell_type":"markdown","id":"68c4b7cc","metadata":{"papermill":{"duration":0.024777,"end_time":"2024-09-08T14:17:43.811063","exception":false,"start_time":"2024-09-08T14:17:43.786286","status":"completed"},"tags":[]},"source":["### Decoder"]},{"cell_type":"code","execution_count":21,"id":"6f472512","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:43.866666Z","iopub.status.busy":"2024-09-08T14:17:43.865543Z","iopub.status.idle":"2024-09-08T14:17:44.033692Z","shell.execute_reply":"2024-09-08T14:17:44.032592Z"},"papermill":{"duration":0.197574,"end_time":"2024-09-08T14:17:44.03675","exception":false,"start_time":"2024-09-08T14:17:43.839176","status":"completed"},"tags":[]},"outputs":[],"source":["# Use Functional API\n","# Inputs\n","decoder_inputs = keras.Input(shape=(None,), name=\"decoder_inputs\") # What has been predicted\n","encoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\") # Output from encoder\n","\n","# Embedding\n","x = keras_nlp.layers.TokenAndPositionEmbedding(\n","    vocabulary_size=SPA_VOCAB_SIZE,\n","    sequence_length=MAX_SEQUENCE_LENGTH,\n","    embedding_dim=EMBED_DIM,\n",")(decoder_inputs)\n","\n","# Decoder layer\n","x = keras_nlp.layers.TransformerDecoder(\n","    intermediate_dim=INTERMEDIATE_DIM,\n","    num_heads=NUM_HEADS\n",")(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n","\n","# Add dropout\n","x = keras.layers.Dropout(0.5)(x)\n","\n","# Outputs\n","decoder_outputs = keras.layers.Dense(SPA_VOCAB_SIZE, activation='softmax')(x)\n","\n","# Define decoder\n","decoder = keras.Model(\n","    [\n","    decoder_inputs,\n","    encoded_seq_inputs,\n","    ],\n","    decoder_outputs\n",")\n","\n","decoder_outputs = decoder([decoder_inputs, encoder_outputs])"]},{"cell_type":"markdown","id":"b6fbe1fa","metadata":{"papermill":{"duration":0.024778,"end_time":"2024-09-08T14:17:44.086462","exception":false,"start_time":"2024-09-08T14:17:44.061684","status":"completed"},"tags":[]},"source":["### Transformer"]},{"cell_type":"code","execution_count":22,"id":"e8a70729","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:44.139553Z","iopub.status.busy":"2024-09-08T14:17:44.138746Z","iopub.status.idle":"2024-09-08T14:17:44.174826Z","shell.execute_reply":"2024-09-08T14:17:44.173603Z"},"papermill":{"duration":0.065771,"end_time":"2024-09-08T14:17:44.177662","exception":false,"start_time":"2024-09-08T14:17:44.111891","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_eng_spa\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"transformer_eng_spa\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ token_and_position… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,240</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionE…</span> │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_encoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,072</span> │ token_and_positi… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ functional_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,283,992</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │ transformer_enco… │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ token_and_position… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,850,240\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mTokenAndPositionE…\u001b[0m │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_encoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,315,072\u001b[0m │ token_and_positi… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ functional_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m9,283,992\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m15000\u001b[0m)            │            │ transformer_enco… │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,449,304</span> (55.12 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,449,304\u001b[0m (55.12 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,449,304</span> (55.12 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,449,304\u001b[0m (55.12 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["transformer1 = keras.Model(\n","    [encoder_inputs, decoder_inputs],\n","    decoder_outputs,\n","    name=\"transformer_eng_spa\"\n",")\n","\n","transformer1.summary()"]},{"cell_type":"code","execution_count":23,"id":"12afedba","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:44.233471Z","iopub.status.busy":"2024-09-08T14:17:44.232348Z","iopub.status.idle":"2024-09-08T14:17:44.250253Z","shell.execute_reply":"2024-09-08T14:17:44.249025Z"},"papermill":{"duration":0.048692,"end_time":"2024-09-08T14:17:44.253125","exception":false,"start_time":"2024-09-08T14:17:44.204433","status":"completed"},"tags":[]},"outputs":[],"source":["# Compile transformer\n","transformer1.compile(optimizer=tf.keras.optimizers.RMSprop(),\n","                   loss=\"sparse_categorical_crossentropy\",\n","                   metrics=['accuracy'])"]},{"cell_type":"markdown","id":"bb1a5e97","metadata":{"papermill":{"duration":0.026091,"end_time":"2024-09-08T14:17:44.306025","exception":false,"start_time":"2024-09-08T14:17:44.279934","status":"completed"},"tags":[]},"source":["### Train Model"]},{"cell_type":"code","execution_count":24,"id":"24674f9d","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:17:44.36396Z","iopub.status.busy":"2024-09-08T14:17:44.36298Z","iopub.status.idle":"2024-09-08T14:24:58.644542Z","shell.execute_reply":"2024-09-08T14:24:58.643233Z"},"papermill":{"duration":434.312688,"end_time":"2024-09-08T14:24:58.647321","exception":false,"start_time":"2024-09-08T14:17:44.334633","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1725805073.177452      86 service.cc:145] XLA service 0x7c0d9c008c20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","I0000 00:00:1725805073.177522      86 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","I0000 00:00:1725805073.177526      86 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","W0000 00:00:1725805073.677383      86 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1725805078.037213     179 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_117', 8 bytes spill stores, 8 bytes spill loads\n","\n","I0000 00:00:1725805087.433021     177 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_117', 968 bytes spill stores, 924 bytes spill loads\n","\n","I0000 00:00:1725805088.401239     178 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_120', 4 bytes spill stores, 4 bytes spill loads\n","\n","I0000 00:00:1725805092.765472     180 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_115', 256 bytes spill stores, 256 bytes spill loads\n","\n","I0000 00:00:1725805095.241160     179 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_112', 256 bytes spill stores, 256 bytes spill loads\n","\n","I0000 00:00:1725805097.353692     178 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_120', 968 bytes spill stores, 924 bytes spill loads\n","\n","I0000 00:00:1725805104.883856     177 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_22', 864 bytes spill stores, 864 bytes spill loads\n","\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m   2/1302\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 82ms/step - accuracy: 0.1896 - loss: 9.1189       "]},{"name":"stderr","output_type":"stream","text":["I0000 00:00:1725805112.334844      86 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 774/1302\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 51ms/step - accuracy: 0.7913 - loss: 1.7800"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1725805152.460128      87 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","I0000 00:00:1725805164.713553     254 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_112', 100 bytes spill stores, 100 bytes spill loads\n","\n","I0000 00:00:1725805173.558432     252 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_120', 1764 bytes spill stores, 1768 bytes spill loads\n","\n","I0000 00:00:1725805179.953062     254 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_117', 1764 bytes spill stores, 1768 bytes spill loads\n","\n","I0000 00:00:1725805180.315888     255 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_115', 340 bytes spill stores, 340 bytes spill loads\n","\n","I0000 00:00:1725805183.201603     253 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_22', 864 bytes spill stores, 864 bytes spill loads\n","\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8238 - loss: 1.4405"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1725805217.522893      87 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","W0000 00:00:1725805221.953565      87 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","I0000 00:00:1725805230.191440     319 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_21', 100 bytes spill stores, 100 bytes spill loads\n","\n","I0000 00:00:1725805232.846417     320 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_24', 340 bytes spill stores, 340 bytes spill loads\n","\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 96ms/step - accuracy: 0.8238 - loss: 1.4400 - val_accuracy: 0.9833 - val_loss: 0.1434\n","Epoch 2/5\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 52ms/step - accuracy: 0.9865 - loss: 0.1153 - val_accuracy: 0.9999 - val_loss: 0.0092\n","Epoch 3/5\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 50ms/step - accuracy: 0.9994 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 8.3736e-04\n","Epoch 4/5\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 50ms/step - accuracy: 0.9995 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 2.7757e-04\n","Epoch 5/5\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 6.5127e-04 - val_accuracy: 1.0000 - val_loss: 1.8397e-04\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x7c0de0145420>"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["transformer1.fit(train_ds,\n","                validation_data=val_ds,\n","                epochs=5,\n","                callbacks=[create_model_checkpoint(transformer1.name)]\n","               )"]},{"cell_type":"markdown","id":"3321135a","metadata":{"papermill":{"duration":0.411242,"end_time":"2024-09-08T14:24:59.541628","exception":false,"start_time":"2024-09-08T14:24:59.130386","status":"completed"},"tags":[]},"source":["## Decoding Test Sentences"]},{"cell_type":"markdown","id":"c28b0664","metadata":{"papermill":{"duration":0.407124,"end_time":"2024-09-08T14:25:00.351895","exception":false,"start_time":"2024-09-08T14:24:59.944771","status":"completed"},"tags":[]},"source":["Use this section to translate brand new test sentences"]},{"cell_type":"code","execution_count":25,"id":"ba593773","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:25:01.228992Z","iopub.status.busy":"2024-09-08T14:25:01.227895Z","iopub.status.idle":"2024-09-08T14:25:01.242345Z","shell.execute_reply":"2024-09-08T14:25:01.2411Z"},"papermill":{"duration":0.488846,"end_time":"2024-09-08T14:25:01.244863","exception":false,"start_time":"2024-09-08T14:25:00.756017","status":"completed"},"tags":[]},"outputs":[],"source":["def decode_sequences(input_sentences, transformer, lan_tokenizer):\n","    batch_size = 1\n","    \n","    # Tokenize encoder input\n","    encoder_input_tokens = ops.convert_to_tensor(eng_tokenizer(input_sentences))\n","    if len(encoder_input_tokens[0]) < MAX_SEQUENCE_LENGTH:\n","        pads = ops.full((1, MAX_SEQUENCE_LENGTH - len(encoder_input_tokens[0])), 0)\n","        encoder_input_tokens = ops.concatenate(\n","            [encoder_input_tokens.to_tensor(), pads], 1\n","        )\n","        \n","    # Define a function that outputs the next tokens probability given the input sequence\n","    def next(prompt, cache, index):\n","        logits = transformer([encoder_input_tokens, prompt])[:, index - 1, :]\n","        # We ignore hidden states for now -> needed only for contrastive search\n","        hidden_states = None\n","        return logits, hidden_states, cache\n","    \n","    # Build a prompt of length 40 with a start token and padding tokens\n","    length = 40\n","    # Add start token\n","    start = ops.full((batch_size, 1), lan_tokenizer.token_to_id(\"[START]\"))\n","    # Add pad token\n","    pad = ops.full((batch_size, length - 1), lan_tokenizer.token_to_id(\"[PAD]\"))\n","    \n","    prompt = ops.concatenate((start, pad), axis=-1)\n","    \n","    # GreedySampler -> Outputs token with highest probability\n","    generated_tokens = keras_nlp.samplers.GreedySampler()(\n","        next,\n","        prompt,\n","        stop_token_ids=[lan_tokenizer.token_to_id(\"[END]\")],\n","        index=1, # Sample only after \"[START]\" token\n","    )\n","    generated_sentences = lan_tokenizer.detokenize(generated_tokens)\n","    return generated_sentences"]},{"cell_type":"code","execution_count":26,"id":"ad3a0b18","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:25:02.056613Z","iopub.status.busy":"2024-09-08T14:25:02.055519Z","iopub.status.idle":"2024-09-08T14:25:11.396667Z","shell.execute_reply":"2024-09-08T14:25:11.395444Z"},"papermill":{"duration":9.747067,"end_time":"2024-09-08T14:25:11.399429","exception":false,"start_time":"2024-09-08T14:25:01.652362","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Example 1\n","i'm tired of listening to his boasts.\n","soldados j policía — piso enseguida lo ;icidio su caído\n","\n","Example 2\n","i always confuse which side is port and which starboard.\n","me ? tío aceptar fotografíala tenés ó m promesas quéla invitótiendoiembre\n","\n"]}],"source":["# Draw English samples from test set\n","test_eng_texts = [pair[0] for pair in test_pairs]\n","\n","for i in range(2):\n","    input_sentence = random.choice(test_eng_texts)\n","    translated = decode_sequences([input_sentence], transformer1, spa_tokenizer)\n","    translated = translated.numpy()[0].decode(\"utf-8\")\n","    \n","    translated = (\n","        translated.replace(\"[PAD]\",\"\")\n","        .replace(\"[START]\",\"\")\n","        .replace(\"[END]\", \"\")\n","        .strip()\n","    )\n","    print(f\"Example {i+1}\")\n","    print(input_sentence)\n","    print(translated)\n","    print()"]},{"cell_type":"markdown","id":"4cea1168","metadata":{"papermill":{"duration":0.404902,"end_time":"2024-09-08T14:25:12.206899","exception":false,"start_time":"2024-09-08T14:25:11.801997","status":"completed"},"tags":[]},"source":["## Evaluate model"]},{"cell_type":"markdown","id":"8d551d48","metadata":{"papermill":{"duration":0.457296,"end_time":"2024-09-08T14:25:13.088582","exception":false,"start_time":"2024-09-08T14:25:12.631286","status":"completed"},"tags":[]},"source":["We are going to use the METEOR score metric to conduct a quantitative analysis of our model"]},{"cell_type":"code","execution_count":null,"id":"1c8068fd","metadata":{"papermill":{"duration":0.398192,"end_time":"2024-09-08T14:25:13.886536","exception":false,"start_time":"2024-09-08T14:25:13.488344","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","id":"14006057","metadata":{"papermill":{"duration":0.404641,"end_time":"2024-09-08T14:25:14.694223","exception":false,"start_time":"2024-09-08T14:25:14.289582","status":"completed"},"tags":[]},"source":["# English-Portuguese"]},{"cell_type":"markdown","id":"4cb44c69","metadata":{"papermill":{"duration":0.404976,"end_time":"2024-09-08T14:25:15.501917","exception":false,"start_time":"2024-09-08T14:25:15.096941","status":"completed"},"tags":[]},"source":["## Setup"]},{"cell_type":"markdown","id":"39a305a0","metadata":{"papermill":{"duration":0.39856,"end_time":"2024-09-08T14:25:16.360844","exception":false,"start_time":"2024-09-08T14:25:15.962284","status":"completed"},"tags":[]},"source":["#### Parse the data"]},{"cell_type":"code","execution_count":27,"id":"96487d4d","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:25:17.166606Z","iopub.status.busy":"2024-09-08T14:25:17.165545Z","iopub.status.idle":"2024-09-08T14:25:18.213042Z","shell.execute_reply":"2024-09-08T14:25:18.21161Z"},"papermill":{"duration":1.452049,"end_time":"2024-09-08T14:25:18.215863","exception":false,"start_time":"2024-09-08T14:25:16.763814","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Vai.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Go.</td>\n","      <td>Vá.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hi.</td>\n","      <td>Oi.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Corre!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Run!</td>\n","      <td>Corra!</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0       1\n","0   Go.    Vai.\n","1   Go.     Vá.\n","2   Hi.     Oi.\n","3  Run!  Corre!\n","4  Run!  Corra!"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["por_eng_df = pd.read_csv('/kaggle/input/por-eng/por-eng/por.txt', header=None, sep=\"\\t\")\n","por_eng_df = por_eng_df.loc[: , :1]\n","por_eng_df.head()"]},{"cell_type":"code","execution_count":28,"id":"7a7cd4a0","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:25:19.027742Z","iopub.status.busy":"2024-09-08T14:25:19.026966Z","iopub.status.idle":"2024-09-08T14:25:19.299927Z","shell.execute_reply":"2024-09-08T14:25:19.298672Z"},"papermill":{"duration":0.678412,"end_time":"2024-09-08T14:25:19.302941","exception":false,"start_time":"2024-09-08T14:25:18.624529","status":"completed"},"tags":[]},"outputs":[],"source":["# Create lists from each data\n","eng_list = por_eng_df.loc[:,0].to_list()\n","por_list = por_eng_df.loc[:,1].to_list()\n","\n","text_pairs = []\n","\n","# Iterate over list and lowercase\n","for i in range(len(eng_list)):\n","    eng = eng_list[i].lower()\n","    por = por_list[i].lower()\n","    \n","    text_pairs.append((eng, por))"]},{"cell_type":"markdown","id":"be125c0a","metadata":{"papermill":{"duration":0.398804,"end_time":"2024-09-08T14:25:20.103859","exception":false,"start_time":"2024-09-08T14:25:19.705055","status":"completed"},"tags":[]},"source":["##### View the sentence pairs"]},{"cell_type":"code","execution_count":29,"id":"f620cefd","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:25:20.966119Z","iopub.status.busy":"2024-09-08T14:25:20.965052Z","iopub.status.idle":"2024-09-08T14:25:20.971609Z","shell.execute_reply":"2024-09-08T14:25:20.970467Z"},"papermill":{"duration":0.409837,"end_time":"2024-09-08T14:25:20.974065","exception":false,"start_time":"2024-09-08T14:25:20.564228","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["('he gave the cat milk.', 'ele deu leite ao gato.')\n","('we have three dogs.', 'nós temos três cachorros.')\n","(\"he's always scowling.\", 'ele anda sempre de cara feia.')\n","('you know tom likes baseball.', 'vocês sabem que o tom gosta de beisebol.')\n","(\"i'll see you the day after tomorrow.\", 'até depois de amanhã.')\n"]}],"source":["for _ in range(5):\n","    print(random.choice(text_pairs))"]},{"cell_type":"markdown","id":"adf891d5","metadata":{"papermill":{"duration":0.399051,"end_time":"2024-09-08T14:25:21.77487","exception":false,"start_time":"2024-09-08T14:25:21.375819","status":"completed"},"tags":[]},"source":["## Preprocessing"]},{"cell_type":"markdown","id":"9d10c3a0","metadata":{"papermill":{"duration":0.428404,"end_time":"2024-09-08T14:25:22.621184","exception":false,"start_time":"2024-09-08T14:25:22.19278","status":"completed"},"tags":[]},"source":["### Split the data"]},{"cell_type":"code","execution_count":30,"id":"7294511b","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:25:23.428258Z","iopub.status.busy":"2024-09-08T14:25:23.427777Z","iopub.status.idle":"2024-09-08T14:25:23.670078Z","shell.execute_reply":"2024-09-08T14:25:23.668801Z"},"papermill":{"duration":0.651901,"end_time":"2024-09-08T14:25:23.672735","exception":false,"start_time":"2024-09-08T14:25:23.020834","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Train size: 135545\n","Validation size: 29044\n","Test size: 29044\n"]}],"source":["random.shuffle(text_pairs)\n","\n","# Set training and validation sizes\n","num_val_samples = int(0.15 * len(text_pairs))\n","num_train_samples = int(len(text_pairs) - 2 * num_val_samples)\n","\n","# Get train, val and test sets\n","train_pairs = text_pairs[: num_train_samples]\n","val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n","test_pairs = text_pairs[num_train_samples + num_val_samples:]\n","\n","print(f\"Train size: {len(train_pairs)}\")\n","print(f\"Validation size: {len(val_pairs)}\")\n","print(f\"Test size: {len(test_pairs)}\")"]},{"cell_type":"markdown","id":"6bd3a0b4","metadata":{"papermill":{"duration":0.405366,"end_time":"2024-09-08T14:25:24.539566","exception":false,"start_time":"2024-09-08T14:25:24.1342","status":"completed"},"tags":[]},"source":["### Tokenization"]},{"cell_type":"code","execution_count":31,"id":"557fe270","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:25:25.351535Z","iopub.status.busy":"2024-09-08T14:25:25.350433Z","iopub.status.idle":"2024-09-08T14:28:09.925625Z","shell.execute_reply":"2024-09-08T14:28:09.924352Z"},"papermill":{"duration":164.985391,"end_time":"2024-09-08T14:28:09.928581","exception":false,"start_time":"2024-09-08T14:25:24.94319","status":"completed"},"tags":[]},"outputs":[],"source":["# Reserve these tokens\n","reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","# Tokenize English samples\n","eng_samples = [text_pair[0] for text_pair in train_pairs]\n","eng_vocab = train_word_piece(eng_samples, ENG_VOCAB_SIZE, reserved_tokens)\n","\n","# Tokenize Portuguese samples\n","por_samples = [text_pair[1] for text_pair in train_pairs]\n","por_vocab = train_word_piece(por_samples, POR_VOCAB_SIZE, reserved_tokens)"]},{"cell_type":"code","execution_count":32,"id":"4bd07273","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:28:10.732481Z","iopub.status.busy":"2024-09-08T14:28:10.731996Z","iopub.status.idle":"2024-09-08T14:28:10.738798Z","shell.execute_reply":"2024-09-08T14:28:10.737673Z"},"papermill":{"duration":0.410447,"end_time":"2024-09-08T14:28:10.741482","exception":false,"start_time":"2024-09-08T14:28:10.331035","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["English tokens:  ['go', 'how', 'll', 'at', 'here', 'there', 've', 'she', 'going', 'they']\n","Portuguese tokens:  ['mais', 'estava', '##s', 'no', 'na', 'estou', 'tem', 'foi', 'nós', 'os']\n"]}],"source":["# View some tokens\n","print(\"English tokens: \", eng_vocab[100:110])\n","print(\"Portuguese tokens: \", por_vocab[100:110])"]},{"cell_type":"markdown","id":"cea9864e","metadata":{"papermill":{"duration":0.400899,"end_time":"2024-09-08T14:28:11.542931","exception":false,"start_time":"2024-09-08T14:28:11.142032","status":"completed"},"tags":[]},"source":["#### Create tokenizers with vocabularies"]},{"cell_type":"code","execution_count":33,"id":"8461fe4c","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:28:12.353166Z","iopub.status.busy":"2024-09-08T14:28:12.352145Z","iopub.status.idle":"2024-09-08T14:28:12.487738Z","shell.execute_reply":"2024-09-08T14:28:12.486594Z"},"papermill":{"duration":0.545973,"end_time":"2024-09-08T14:28:12.490737","exception":false,"start_time":"2024-09-08T14:28:11.944764","status":"completed"},"tags":[]},"outputs":[],"source":["# English tokenizer\n","eng_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=eng_vocab,\n","    lowercase=False\n",")\n","\n","# Portuguese tokenizer\n","por_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=por_vocab,\n","    lowercase=False\n",")"]},{"cell_type":"code","execution_count":34,"id":"e2890f37","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:28:13.355175Z","iopub.status.busy":"2024-09-08T14:28:13.354416Z","iopub.status.idle":"2024-09-08T14:28:13.376906Z","shell.execute_reply":"2024-09-08T14:28:13.37581Z"},"papermill":{"duration":0.424852,"end_time":"2024-09-08T14:28:13.379742","exception":false,"start_time":"2024-09-08T14:28:12.95489","status":"completed"},"tags":[]},"outputs":[],"source":["# Saving tokenizers\n","# English\n","with open('tokenizer_engpor_eng.pickle', 'wb') as handle:\n","    pickle.dump(eng_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","# Portuguese\n","with open('tokenizer_engpor_por.pickle', 'wb') as handle:\n","    pickle.dump(por_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":35,"id":"479cd518","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:28:14.184036Z","iopub.status.busy":"2024-09-08T14:28:14.183124Z","iopub.status.idle":"2024-09-08T14:28:14.241477Z","shell.execute_reply":"2024-09-08T14:28:14.240082Z"},"papermill":{"duration":0.462792,"end_time":"2024-09-08T14:28:14.244274","exception":false,"start_time":"2024-09-08T14:28:13.781482","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Original sentence:  don't open it.\n","Tokenized output:  tf.Tensor([ 76   9  45 296  70  12], shape=(6,), dtype=int32)\n","Recovered text after tokenizing:  tf.Tensor(b\"don ' t open it .\", shape=(), dtype=string)\n","\n","Original sentence:  não o abram.\n","Tokenized output:  tf.Tensor([  81   42 4613   13], shape=(4,), dtype=int32)\n","Recovered text after tokenizing:  tf.Tensor(b'n\\xc3\\xa3o o abram .', shape=(), dtype=string)\n"]}],"source":["# Test English tokenizer on a sample\n","eng_input_eg = text_pairs[0][0]\n","eng_token_eg = eng_tokenizer(eng_input_eg)\n","print(\"Original sentence: \", eng_input_eg)\n","print(\"Tokenized output: \", eng_token_eg)\n","print(\"Recovered text after tokenizing: \", eng_tokenizer.detokenize(eng_token_eg))\n","\n","print()\n","# Test Portuguese tokenizer on a sample\n","por_input_eg = text_pairs[0][1]\n","por_token_eg = por_tokenizer(por_input_eg)\n","print(\"Original sentence: \", por_input_eg)\n","print(\"Tokenized output: \", por_token_eg)\n","print(\"Recovered text after tokenizing: \", por_tokenizer.detokenize(por_token_eg))"]},{"cell_type":"markdown","id":"14623f2f","metadata":{"papermill":{"duration":0.402665,"end_time":"2024-09-08T14:28:15.069823","exception":false,"start_time":"2024-09-08T14:28:14.667158","status":"completed"},"tags":[]},"source":["### Format datasets"]},{"cell_type":"code","execution_count":36,"id":"3ce9254b","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:28:15.875516Z","iopub.status.busy":"2024-09-08T14:28:15.874684Z","iopub.status.idle":"2024-09-08T14:28:20.044376Z","shell.execute_reply":"2024-09-08T14:28:20.043273Z"},"papermill":{"duration":4.57676,"end_time":"2024-09-08T14:28:20.048173","exception":false,"start_time":"2024-09-08T14:28:15.471413","status":"completed"},"tags":[]},"outputs":[],"source":["train_ds = make_dataset(train_pairs)\n","val_ds = make_dataset(val_pairs)"]},{"cell_type":"code","execution_count":37,"id":"7b1d5501","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:28:20.85733Z","iopub.status.busy":"2024-09-08T14:28:20.856908Z","iopub.status.idle":"2024-09-08T14:28:22.852976Z","shell.execute_reply":"2024-09-08T14:28:22.851526Z"},"papermill":{"duration":2.403606,"end_time":"2024-09-08T14:28:22.855663","exception":false,"start_time":"2024-09-08T14:28:20.452057","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["inputs[\"encoder_inputs\"].shape: (64, 40)\n","inputs[\"decoder_inputs\"].shape: (64, 40)\n","targets.shape: (64, 40)\n"]}],"source":["# Look at sequence shapes\n","for inputs, target in train_ds.take(1):\n","    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n","    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n","    print(f\"targets.shape: {targets.shape}\")"]},{"cell_type":"markdown","id":"faf5d19f","metadata":{"papermill":{"duration":0.468315,"end_time":"2024-09-08T14:28:23.728933","exception":false,"start_time":"2024-09-08T14:28:23.260618","status":"completed"},"tags":[]},"source":["## Model Construction"]},{"cell_type":"markdown","id":"fcacc0a4","metadata":{"papermill":{"duration":0.401966,"end_time":"2024-09-08T14:28:24.537534","exception":false,"start_time":"2024-09-08T14:28:24.135568","status":"completed"},"tags":[]},"source":["### Encoder"]},{"cell_type":"code","execution_count":38,"id":"6d182172","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:28:25.341424Z","iopub.status.busy":"2024-09-08T14:28:25.340942Z","iopub.status.idle":"2024-09-08T14:28:25.443279Z","shell.execute_reply":"2024-09-08T14:28:25.442163Z"},"papermill":{"duration":0.510029,"end_time":"2024-09-08T14:28:25.44628","exception":false,"start_time":"2024-09-08T14:28:24.936251","status":"completed"},"tags":[]},"outputs":[],"source":["# Inputs\n","encoder_inputs = keras.Input(shape=(None,), name=\"encoder_inputs\")\n","\n","# Embedding\n","x = keras_nlp.layers.TokenAndPositionEmbedding(\n","    vocabulary_size=ENG_VOCAB_SIZE,\n","    sequence_length=MAX_SEQUENCE_LENGTH,\n","    embedding_dim=EMBED_DIM\n",")(encoder_inputs)\n","\n","# Outputs\n","encoder_outputs = keras_nlp.layers.TransformerEncoder(\n","    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",")(inputs=x)\n","\n","# Define encoder\n","encoder = keras.Model(encoder_inputs, encoder_outputs)"]},{"cell_type":"markdown","id":"8f09c282","metadata":{"papermill":{"duration":0.402001,"end_time":"2024-09-08T14:28:26.312623","exception":false,"start_time":"2024-09-08T14:28:25.910622","status":"completed"},"tags":[]},"source":["### Decoder"]},{"cell_type":"code","execution_count":39,"id":"a4600166","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:28:27.118288Z","iopub.status.busy":"2024-09-08T14:28:27.117248Z","iopub.status.idle":"2024-09-08T14:28:27.276646Z","shell.execute_reply":"2024-09-08T14:28:27.275586Z"},"papermill":{"duration":0.563617,"end_time":"2024-09-08T14:28:27.279477","exception":false,"start_time":"2024-09-08T14:28:26.71586","status":"completed"},"tags":[]},"outputs":[],"source":["# Inputs\n","decoder_inputs = keras.Input(shape=(None,), name=\"decoder_inputs\") # What we already predicted\n","encoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\") # Output from encoder to go to the next word\n","\n","# Embedding\n","x = keras_nlp.layers.TokenAndPositionEmbedding(\n","    vocabulary_size=POR_VOCAB_SIZE,\n","    sequence_length=MAX_SEQUENCE_LENGTH,\n","    embedding_dim=EMBED_DIM\n",")(decoder_inputs)\n","\n","# Decoder layer\n","x = keras_nlp.layers.TransformerDecoder(\n","    intermediate_dim=INTERMEDIATE_DIM,\n","    num_heads=NUM_HEADS\n",")(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n","\n","# Add dropout\n","x = keras.layers.Dropout(0.5)(x)\n","\n","# Outputs\n","decoder_outputs = keras.layers.Dense(POR_VOCAB_SIZE, activation='softmax')(x)\n","\n","# Define decoder\n","decoder = keras.Model(\n","    [\n","        decoder_inputs,\n","        encoded_seq_inputs\n","    ],\n","    decoder_outputs\n",")\n","\n","decoder_outputs = decoder([decoder_inputs, encoder_outputs])"]},{"cell_type":"markdown","id":"5bf4fefc","metadata":{"papermill":{"duration":0.461219,"end_time":"2024-09-08T14:28:28.14315","exception":false,"start_time":"2024-09-08T14:28:27.681931","status":"completed"},"tags":[]},"source":["### Transformer"]},{"cell_type":"code","execution_count":40,"id":"220d4473","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:28:28.945353Z","iopub.status.busy":"2024-09-08T14:28:28.944897Z","iopub.status.idle":"2024-09-08T14:28:28.97776Z","shell.execute_reply":"2024-09-08T14:28:28.976648Z"},"papermill":{"duration":0.438459,"end_time":"2024-09-08T14:28:28.980225","exception":false,"start_time":"2024-09-08T14:28:28.541766","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_eng_por\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"transformer_eng_por\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ token_and_position… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,240</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionE…</span> │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,072</span> │ token_and_positi… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ functional_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,283,992</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │ transformer_enco… │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ token_and_position… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,850,240\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mTokenAndPositionE…\u001b[0m │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,315,072\u001b[0m │ token_and_positi… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ functional_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m9,283,992\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m15000\u001b[0m)            │            │ transformer_enco… │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,449,304</span> (55.12 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,449,304\u001b[0m (55.12 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,449,304</span> (55.12 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,449,304\u001b[0m (55.12 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["transformer2 = keras.Model(\n","    [encoder_inputs, decoder_inputs],\n","    decoder_outputs,\n","    name=\"transformer_eng_por\"\n",")\n","\n","transformer2.summary()"]},{"cell_type":"code","execution_count":41,"id":"d57ea033","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:28:29.783167Z","iopub.status.busy":"2024-09-08T14:28:29.782358Z","iopub.status.idle":"2024-09-08T14:28:29.794849Z","shell.execute_reply":"2024-09-08T14:28:29.793793Z"},"papermill":{"duration":0.416392,"end_time":"2024-09-08T14:28:29.797817","exception":false,"start_time":"2024-09-08T14:28:29.381425","status":"completed"},"tags":[]},"outputs":[],"source":["# Compile transformer\n","transformer2.compile(optimizer=tf.keras.optimizers.RMSprop(),\n","                   loss='sparse_categorical_crossentropy',\n","                   metrics=['accuracy'])"]},{"cell_type":"markdown","id":"ea05bdc9","metadata":{"papermill":{"duration":0.400958,"end_time":"2024-09-08T14:28:30.602537","exception":false,"start_time":"2024-09-08T14:28:30.201579","status":"completed"},"tags":[]},"source":["### Train Model"]},{"cell_type":"code","execution_count":42,"id":"1c53ed1f","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-09-08T14:28:31.476276Z","iopub.status.busy":"2024-09-08T14:28:31.475126Z","iopub.status.idle":"2024-09-08T14:46:29.662643Z","shell.execute_reply":"2024-09-08T14:46:29.661347Z"},"papermill":{"duration":1080.177784,"end_time":"2024-09-08T14:46:31.242075","exception":false,"start_time":"2024-09-08T14:28:31.064291","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1725805720.777704      86 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 367/2118\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 53ms/step - accuracy: 0.6265 - loss: 2.8100"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1725805747.931022      88 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","I0000 00:00:1725805765.487832     534 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_22', 864 bytes spill stores, 864 bytes spill loads\n","\n","I0000 00:00:1725805769.288029     531 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_112', 100 bytes spill stores, 100 bytes spill loads\n","\n","I0000 00:00:1725805773.851780     534 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_115', 340 bytes spill stores, 340 bytes spill loads\n","\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2117/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6644 - loss: 1.9936"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1725805869.873779      88 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","W0000 00:00:1725805871.386056      88 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 71ms/step - accuracy: 0.6644 - loss: 1.9933 - val_accuracy: 0.7256 - val_loss: 1.4084\n","Epoch 2/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 51ms/step - accuracy: 0.7551 - loss: 1.2627 - val_accuracy: 0.9937 - val_loss: 0.0430\n","Epoch 3/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 48ms/step - accuracy: 0.9946 - loss: 0.0358 - val_accuracy: 0.9986 - val_loss: 0.0110\n","Epoch 4/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 48ms/step - accuracy: 0.9986 - loss: 0.0108 - val_accuracy: 0.9995 - val_loss: 0.0044\n","Epoch 5/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 48ms/step - accuracy: 0.9992 - loss: 0.0065 - val_accuracy: 0.9997 - val_loss: 0.0024\n","Epoch 6/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 47ms/step - accuracy: 0.9997 - loss: 0.0026 - val_accuracy: 0.9998 - val_loss: 0.0016\n","Epoch 7/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 47ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9999 - val_loss: 0.0012\n","Epoch 8/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 47ms/step - accuracy: 0.9997 - loss: 0.0028 - val_accuracy: 0.9999 - val_loss: 7.3404e-04\n","Epoch 9/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 46ms/step - accuracy: 0.9999 - loss: 7.9114e-04 - val_accuracy: 0.9999 - val_loss: 5.6799e-04\n","Epoch 10/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 46ms/step - accuracy: 0.9999 - loss: 8.8430e-04 - val_accuracy: 1.0000 - val_loss: 4.6044e-04\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x7c09cef1f670>"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["transformer2.fit(train_ds, validation_data=[val_ds],\n","               epochs=10,\n","               callbacks=[create_model_checkpoint(transformer2.name)])"]},{"cell_type":"markdown","id":"7c8ff437","metadata":{"papermill":{"duration":1.577842,"end_time":"2024-09-08T14:46:34.384672","exception":false,"start_time":"2024-09-08T14:46:32.80683","status":"completed"},"tags":[]},"source":["## Decoding Test Sentences"]},{"cell_type":"code","execution_count":43,"id":"1a6f925d","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:46:37.449267Z","iopub.status.busy":"2024-09-08T14:46:37.448813Z","iopub.status.idle":"2024-09-08T14:46:43.715037Z","shell.execute_reply":"2024-09-08T14:46:43.713623Z"},"papermill":{"duration":7.759453,"end_time":"2024-09-08T14:46:43.71819","exception":false,"start_time":"2024-09-08T14:46:35.958737","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Example1\n","what's your favorite christmas carol?\n","( q com motivado forte estardico :\n","\n","Example2\n","this analysis is divided in two parts.\n","adicione conseguido fonte meu campainha õ nomes entanto insistiu tomatesico\n","\n"]}],"source":["# Draw English samples from test set\n","test_eng_texts = [pair[0] for pair in test_pairs]\n","\n","# Output 2 example translations\n","for i in range(2):\n","    input_sentence = random.choice(test_eng_texts)\n","    translated = decode_sequences([input_sentence], transformer2, por_tokenizer)\n","    translated = translated.numpy()[0].decode('utf-8')\n","    \n","    translated = (\n","        translated.replace(\"[PAD]\", \"\")\n","        .replace(\"[UNK]\", \"\")\n","        .replace(\"[START]\", \"\")\n","        .replace(\"[END]\", \"\")\n","        .strip()\n","    )\n","    print(f\"Example{i+1}\")\n","    print(input_sentence)\n","    print(translated)\n","    print()"]},{"cell_type":"markdown","id":"5a73f6e7","metadata":{"papermill":{"duration":1.497411,"end_time":"2024-09-08T14:46:46.789536","exception":false,"start_time":"2024-09-08T14:46:45.292125","status":"completed"},"tags":[]},"source":["# English-Aymara"]},{"cell_type":"markdown","id":"222a4da6","metadata":{"papermill":{"duration":1.573912,"end_time":"2024-09-08T14:46:49.937804","exception":false,"start_time":"2024-09-08T14:46:48.363892","status":"completed"},"tags":[]},"source":["The dataset for English to Aymara is significantly smaller (sourced from HuggingFace) and consists of specific words rather than sentences as the other datasets have. If more, higher quality data becomes available, this project will be updated."]},{"cell_type":"markdown","id":"7a3e5813","metadata":{"papermill":{"duration":1.602851,"end_time":"2024-09-08T14:46:53.034846","exception":false,"start_time":"2024-09-08T14:46:51.431995","status":"completed"},"tags":[]},"source":["## Setup"]},{"cell_type":"markdown","id":"234e088a","metadata":{"papermill":{"duration":1.501556,"end_time":"2024-09-08T14:46:56.114672","exception":false,"start_time":"2024-09-08T14:46:54.613116","status":"completed"},"tags":[]},"source":["### Import English-Aymara dataset"]},{"cell_type":"code","execution_count":44,"id":"8cf8557c","metadata":{"execution":{"iopub.execute_input":"2024-09-08T14:46:59.249922Z","iopub.status.busy":"2024-09-08T14:46:59.248931Z","iopub.status.idle":"2024-09-08T14:46:59.791941Z","shell.execute_reply":"2024-09-08T14:46:59.790702Z"},"papermill":{"duration":2.11603,"end_time":"2024-09-08T14:46:59.794925","exception":false,"start_time":"2024-09-08T14:46:57.678895","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Aymara</th>\n","      <th>English</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>achachi</td>\n","      <td>grandfather</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>achachila</td>\n","      <td>grandfather</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>achachilan tatapa</td>\n","      <td>great grandfather</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>achacu</td>\n","      <td>mouse</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>achaku</td>\n","      <td>mouse</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Aymara            English\n","0            achachi        grandfather\n","1          achachila        grandfather\n","2  achachilan tatapa  great grandfather\n","3             achacu              mouse\n","4             achaku              mouse"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["eng_aym = pd.read_csv(\"hf://datasets/alvations/aymara-english/aymara-english.tsv\", sep=\"\\t\")\n","eng_aym.head()"]},{"cell_type":"code","execution_count":null,"id":"d3582164","metadata":{"papermill":{"duration":1.561869,"end_time":"2024-09-08T14:47:02.977386","exception":false,"start_time":"2024-09-08T14:47:01.415517","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5611402,"sourceId":9272285,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":2022.360539,"end_time":"2024-09-08T14:47:08.207015","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-08T14:13:25.846476","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}